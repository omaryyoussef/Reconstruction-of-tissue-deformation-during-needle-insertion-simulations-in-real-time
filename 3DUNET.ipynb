{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from numpy import ndarray\n",
    "import SimpleITK\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0005\n",
    "batch = 48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, target, transform = None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load train data\n",
    "\n",
    "train_dataset = Dataset(np.load('forcetrain.npy'), np.load('disptrain.npy'))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory = True \n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    print('Train Batch idx {}, force shape {}, displacement shape {}'.format(\n",
    "        batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "\n",
    "test_dataset = Dataset(np.load('forcetest.npy'), np.load('disptest.npy'))\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory = True \n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    print('Test Batch idx {}, force shape {}, displacement shape {}'.format(\n",
    "        batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main 3D UNET blocks\n",
    "\n",
    "def conv_block_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)\n",
    "\n",
    "\n",
    "def conv_trans_block_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose3d(in_dim, out_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)\n",
    "\n",
    "\n",
    "def max_pooling_3d():\n",
    "    return nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "\n",
    "def conv_block_2_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        conv_block_3d(in_dim, out_dim, activation),\n",
    "        nn.Conv3d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_filters):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_filters = num_filters\n",
    "        activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Down sampling\n",
    "        self.down_1 = conv_block_2_3d(self.in_dim, self.num_filters, activation)\n",
    "        self.pool_1 = max_pooling_3d()\n",
    "        self.down_2 = conv_block_2_3d(self.num_filters, self.num_filters * 2, activation)\n",
    "        self.pool_2 = max_pooling_3d()\n",
    "        self.down_3 = conv_block_2_3d(self.num_filters * 2, self.num_filters * 4, activation)\n",
    "        self.pool_3 = max_pooling_3d()\n",
    "        self.down_4 = conv_block_2_3d(self.num_filters * 4, self.num_filters * 8, activation)\n",
    "        self.pool_4 = max_pooling_3d()\n",
    "        self.down_5 = conv_block_2_3d(self.num_filters * 8, self.num_filters * 16, activation)\n",
    "        self.pool_5 = max_pooling_3d()\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = conv_block_2_3d(self.num_filters * 16, self.num_filters * 32, activation)\n",
    "        \n",
    "        # Up sampling\n",
    "        self.trans_1 = conv_trans_block_3d(self.num_filters * 32, self.num_filters * 32, activation)\n",
    "        self.up_1 = conv_block_2_3d(self.num_filters * 48, self.num_filters * 16, activation)\n",
    "        self.trans_2 = conv_trans_block_3d(self.num_filters * 16, self.num_filters * 16, activation)\n",
    "        self.up_2 = conv_block_2_3d(self.num_filters * 24, self.num_filters * 8, activation)\n",
    "        self.trans_3 = conv_trans_block_3d(self.num_filters * 8, self.num_filters * 8, activation)\n",
    "        self.up_3 = conv_block_2_3d(self.num_filters * 12, self.num_filters * 4, activation)\n",
    "        self.trans_4 = conv_trans_block_3d(self.num_filters * 4, self.num_filters * 4, activation)\n",
    "        self.up_4 = conv_block_2_3d(self.num_filters * 6, self.num_filters * 2, activation)\n",
    "        self.trans_5 = conv_trans_block_3d(self.num_filters * 2, self.num_filters * 2, activation)\n",
    "        self.up_5 = conv_block_2_3d(self.num_filters * 3, self.num_filters * 1, activation)\n",
    "        \n",
    "        # Output\n",
    "        self.out = conv_block_3d(self.num_filters, out_dim, activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Down sampling\n",
    "        down_1 = self.down_1(x) \n",
    "        pool_1 = self.pool_1(down_1) \n",
    "        \n",
    "        down_2 = self.down_2(pool_1) \n",
    "        pool_2 = self.pool_2(down_2) \n",
    "        \n",
    "        down_3 = self.down_3(pool_2) \n",
    "        pool_3 = self.pool_3(down_3) \n",
    "        \n",
    "        down_4 = self.down_4(pool_3) \n",
    "        pool_4 = self.pool_4(down_4) \n",
    "        \n",
    "        down_5 = self.down_5(pool_4) \n",
    "        pool_5 = self.pool_5(down_5) \n",
    "        \n",
    "        # Skip Connection\n",
    "        bridge = self.bridge(pool_5) \n",
    "        \n",
    "        # Upsampling\n",
    "        trans_1 = self.trans_1(bridge) \n",
    "        concat_1 = torch.cat([trans_1, down_5], dim=1) \n",
    "        up_1 = self.up_1(concat_1) \n",
    "        \n",
    "        trans_2 = self.trans_2(up_1) \n",
    "        concat_2 = torch.cat([trans_2, down_4], dim=1) \n",
    "        up_2 = self.up_2(concat_2) \n",
    "        \n",
    "        trans_3 = self.trans_3(up_2) \n",
    "        concat_3 = torch.cat([trans_3, down_3], dim=1) \n",
    "        up_3 = self.up_3(concat_3) \n",
    "        \n",
    "        trans_4 = self.trans_4(up_3) \n",
    "        concat_4 = torch.cat([trans_4, down_2], dim=1) \n",
    "        up_4 = self.up_4(concat_4) \n",
    "        \n",
    "        trans_5 = self.trans_5(up_4) \n",
    "        concat_5 = torch.cat([trans_5, down_1], dim=1) \n",
    "        up_5 = self.up_5(concat_5) \n",
    "        \n",
    "        # Output\n",
    "        out = self.out(up_5)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_dim = 3, out_dim = 3, num_filters = 4).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25,50,75], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "loss_values = []\n",
    "loss_values_test = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_loss_test = 0.0\n",
    "\n",
    "    \n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        forcet = data.to(device)\n",
    "        dispt = target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(forcet)\n",
    "        loss = criterion(outputs, dispt)\n",
    "        running_loss =+ loss.item() * forcet.size(0)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "         \n",
    "     \n",
    "    loss_values.append(running_loss / len(train_loader))\n",
    "     \n",
    "    \n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            forceTest = data.to(device)\n",
    "            dispTest = target.to(device)\n",
    "            outputs_test = model(forceTest)\n",
    "            loss = criterion(outputs_test, dispTest)\n",
    "            running_loss_test =+ loss.item() * forceTest.size(0)\n",
    "        \n",
    "    \n",
    "    loss_values_test.append(running_loss_test / len(train_loader)) \n",
    "    #scheduler.step()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_values, label = 'Training Loss')\n",
    "ax.plot(loss_values_test, label = 'Validation Loss')\n",
    "ax.set(xlabel='No. of Epochs', ylabel ='Loss',\n",
    "       title='Training Results')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "#fig.savefig(\"200ep-0.0001lr-48batchsize.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training output\n",
    "out_train = outputs.detach().cpu().numpy()\n",
    "out1_train = out_train[-1]\n",
    "out2_train = np.swapaxes(out1_train, 0, 3)\n",
    "out2_train.shape\n",
    "\n",
    "# Training output plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(out2_train[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training groundtruth\n",
    "true_train = dispt.detach().cpu().numpy()\n",
    "true1_train = true_train[-1]\n",
    "true2_train = np.swapaxes(true1_train, 0, 3)\n",
    "true2_train.shape\n",
    "\n",
    "# Training groundtruth plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(true2_train[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation output\n",
    "out_valid = outputs_test.cpu().numpy()\n",
    "out1_valid = out_valid[-1]\n",
    "out2_valid = np.swapaxes(out1_valid, 0, 3)\n",
    "out2_valid.shape\n",
    "\n",
    "# Validation output plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(out2_valid[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation set groundtruth\n",
    "true_valid = dispTest.cpu().numpy()\n",
    "true1_valid = true_valid[-1]\n",
    "true2_valid = np.swapaxes(true1_valid, 0, 3)\n",
    "true2_valid.shape\n",
    "\n",
    "# Validation set groundtruth plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(true2_valid[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = forcet.detach().cpu().numpy()\n",
    "test_input = forceTest.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainip = np.swapaxes(train_input[-1], 0, 3)\n",
    "testip = np.swapaxes(test_input[-1], 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(true_train))\n",
    "print(np.shape(out_train))\n",
    "print(np.shape(true_valid))\n",
    "print(np.shape(out_valid))\n",
    "print(np.shape(train_input))\n",
    "print(np.shape(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('truetrain.npy', true_train)\n",
    "np.save('outtrain.npy', out_train)\n",
    "np.save('truevalid.npy', true_valid)\n",
    "np.save('outvalid.npy', out_valid)\n",
    "np.save('traininput.npy', train_input)\n",
    "np.save('testinput.npy', test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/home/oyoussef/250epochs-48batch-0.001lr-SmoothL1Loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_raw(data: ndarray, filename):\n",
    "    \"\"\"\n",
    "    Writes data to a .raw and .mhd file.\n",
    "\n",
    "    The provided data will be written to the filesystem as a .mhd file\n",
    "    containing the information and a .raw containing the actual data.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The data which will be printed in the file.\n",
    "        filename: The name of the file. It has to end with .mhd.\n",
    "    \"\"\"\n",
    "\n",
    "    if not filename.endswith(\".mhd\"):\n",
    "        raise FileExtensionError(\"Provided file has to be of type .mhd\")\n",
    "\n",
    "    image = SimpleITK.GetImageFromArray(data)\n",
    "    f = open(filename, \"w\")\n",
    "    SimpleITK.WriteImage(image, filename)\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the data as metaimages for visualization in Paraview\n",
    "\n",
    "write_raw(out2_train, 'Training_Output.mhd')\n",
    "write_raw(true2_train, 'Training_GT.mhd')\n",
    "\n",
    "write_raw(out2_valid, 'Validation_Output.mhd')\n",
    "write_raw(true2_valid, 'Validation_GT.mhd')\n",
    "\n",
    "write_raw(trainip, 'Training_Input.mhd')\n",
    "write_raw(testip, 'Validation_Input.mhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_iter = iter(test_loader)\n",
    "#data = train_iter.next()\n",
    "#x, y = data\t\t\n",
    "#y.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_values, label = 'Training Loss')\n",
    "ax.plot(loss_values_test, label = 'Validation Loss')\n",
    "ax.set(xlabel='No. of Epochs', ylabel='Loss',\n",
    "       title='Training Results')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "fig.savefig(\"100ep-0.0005lr-valtrainlosses.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet(in_dim=3, out_dim=3, num_filters=4).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "loss_values = []\n",
    "outputs_a = []\n",
    "total_step = len(loader)\n",
    "running_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        forcet = data.to(device)\n",
    "        dispt = target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(forcet)\n",
    "        loss = criterion(outputs, dispt)\n",
    "        #loss_values.append(loss.item())\n",
    "        running_loss =+ loss.item()\n",
    "        \n",
    "\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    \n",
    "    loss_values.append(running_loss / len(loader))\n",
    "    outputs_a.append(outputs)\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_values)\n",
    "ax.set(xlabel='No. of Epochs', ylabel='Training Loss',\n",
    "       title='Training Results')\n",
    "ax.grid()\n",
    "#fig.savefig(\"200ep-0.0005lr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '/home/oyoussef/200epochs-12batch-0.0005lr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "running_loss = 0.0\n",
    "total_step = len(test_loader)\n",
    "loss_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, (data, target) in  enumerate(test_loader):\n",
    "        forceTest = data.to(device)\n",
    "        dispTest = target.to(device)\n",
    "        outputs = model(forceTest)\n",
    "        loss = criterion(outputs, dispTest)\n",
    "        running_loss =+ loss.item()\n",
    "        \n",
    "        #print ('Step [{}/{}], Loss: {:.4f}' .format(total_step, loss.item()))\n",
    "\n",
    "    dloss_values.append(running_loss / len(test_loader))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_values)\n",
    "ax.set(xlabel='Batch No.', ylabel='Validation Loss',\n",
    "       title='Validation Results')\n",
    "ax.grid()\n",
    "plt.show()\n",
    "# Save the model checkpoint\n",
    "#torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "c = torch.cuda.memory_cached(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = c-a  # free inside cache\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizations:\n",
    "    def __init__(self, env_name=None):\n",
    "        if env_name is None:\n",
    "            env_name = str(datetime.now().strftime(\"%d-%m %Hh%M\"))\n",
    "        self.env_name = env_name\n",
    "        self.vis = visdom.Visdom(env=self.env_name)\n",
    "        self.loss_win = None\n",
    "\n",
    "    def plot_loss(self, loss, step):\n",
    "        self.loss_win = self.vis.line(\n",
    "            [loss],\n",
    "            [step],\n",
    "            win=self.loss_win,\n",
    "            update='append' if self.loss_win else None,\n",
    "            opts=dict(\n",
    "                xlabel='Step',\n",
    "                ylabel='Loss',\n",
    "                title='Loss (mean per 10 steps)',\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bokeh\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from functools import partial\n",
    "from threading import Thread\n",
    "from tornado import gen\n",
    "\n",
    "\n",
    "source = ColumnDataSource(data={'epochs': [],\n",
    " 'trainlosses': []}\n",
    ")\n",
    "\n",
    "plot = figure()\n",
    "plot.line(x= 'epochs', y='trainlosses',\n",
    " color='green', alpha=0.8, legend='Train loss', line_width=2,\n",
    " source=source)\n",
    "\n",
    "doc = curdoc()\n",
    "# Add the plot to the current document\n",
    "doc.add_root(plot)\n",
    "\n",
    "@gen.coroutine\n",
    "def update(new_data):\n",
    "    source.stream(new_data)\n",
    "\n",
    "\n",
    "model = UNet(in_dim=3, out_dim=3, num_filters=4).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "def train(num_epochs):\n",
    "    \n",
    "    total_step = len(loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, target) in enumerate(loader):\n",
    "            forcet = data.to(device)\n",
    "            dispt = target.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(forcet)\n",
    "            loss = criterion(outputs, dispt)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            # Visualize\n",
    "            new_data = {'epochs': [num_epochs],\n",
    "                'trainlosses': [loss]}\n",
    "            doc.add_next_tick_callback(partial(update, new_data))\n",
    "\n",
    "            if (i+1) % 2 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "                \n",
    "\n",
    "thread = Thread(target=train)\n",
    "thread.start()\n",
    "train(num_epochs)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing i/p and o/p shape of the model\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    " # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  #dim_size = 64\n",
    "  #x = torch.Tensor(22, 3, dim_size, dim_size, dim_size)\n",
    "  #x.to(device)\n",
    "  #print(\"x size: {}\".format(x.size()))\n",
    "  \n",
    "  #model = UNet(in_dim=3, out_dim=3, num_filters=4)\n",
    "  \n",
    "  #out = model(x)\n",
    "  #print(\"out size: {}\".format(out.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_dim=3, out_dim=3, num_filters=4).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "data_loaders = {\"train\": loader, \"val\": test_loader}\n",
    "data_lengths = {\"train\": len(loader), \"val\": len(test_loader)}\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            model.train(True)\n",
    "        else: \n",
    "            model.train(False)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        for data in data_loaders[phase]:\n",
    "            \n",
    "            forcet = data['data']\n",
    "            dispt = data['target']\n",
    "            outputs = model(forcet)\n",
    "            loss = criterion(outputs, dispt)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                # update the weights\n",
    "                optimizer.step()\n",
    "            \n",
    "            # print loss statistics\n",
    "            running_loss =+ loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / data_lengths[phase]\n",
    "        print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
