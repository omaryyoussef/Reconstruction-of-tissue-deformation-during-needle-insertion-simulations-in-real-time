{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from numpy import ndarray\n",
    "import SimpleITK\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0005\n",
    "batch = 48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, target, transform = None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load train data\n",
    "\n",
    "train_dataset = Dataset(np.load('forcetrain.npy'), np.load('disptrain.npy'))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory = True \n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    print('Train Batch idx {}, force shape {}, displacement shape {}'.format(\n",
    "        batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "\n",
    "test_dataset = Dataset(np.load('forcetest.npy'), np.load('disptest.npy'))\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory = True \n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    print('Test Batch idx {}, force shape {}, displacement shape {}'.format(\n",
    "        batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main 3D UNET blocks\n",
    "\n",
    "def conv_block_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)\n",
    "\n",
    "\n",
    "def conv_trans_block_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose3d(in_dim, out_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)\n",
    "\n",
    "\n",
    "def max_pooling_3d():\n",
    "    return nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "\n",
    "def conv_block_2_3d(in_dim, out_dim, activation):\n",
    "    return nn.Sequential(\n",
    "        conv_block_3d(in_dim, out_dim, activation),\n",
    "        nn.Conv3d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm3d(out_dim),\n",
    "        activation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_filters):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_filters = num_filters\n",
    "        activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Down sampling\n",
    "        self.down_1 = conv_block_2_3d(self.in_dim, self.num_filters, activation)\n",
    "        self.pool_1 = max_pooling_3d()\n",
    "        self.down_2 = conv_block_2_3d(self.num_filters, self.num_filters * 2, activation)\n",
    "        self.pool_2 = max_pooling_3d()\n",
    "        self.down_3 = conv_block_2_3d(self.num_filters * 2, self.num_filters * 4, activation)\n",
    "        self.pool_3 = max_pooling_3d()\n",
    "        self.down_4 = conv_block_2_3d(self.num_filters * 4, self.num_filters * 8, activation)\n",
    "        self.pool_4 = max_pooling_3d()\n",
    "        self.down_5 = conv_block_2_3d(self.num_filters * 8, self.num_filters * 16, activation)\n",
    "        self.pool_5 = max_pooling_3d()\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = conv_block_2_3d(self.num_filters * 16, self.num_filters * 32, activation)\n",
    "        \n",
    "        # Up sampling\n",
    "        self.trans_1 = conv_trans_block_3d(self.num_filters * 32, self.num_filters * 32, activation)\n",
    "        self.up_1 = conv_block_2_3d(self.num_filters * 48, self.num_filters * 16, activation)\n",
    "        self.trans_2 = conv_trans_block_3d(self.num_filters * 16, self.num_filters * 16, activation)\n",
    "        self.up_2 = conv_block_2_3d(self.num_filters * 24, self.num_filters * 8, activation)\n",
    "        self.trans_3 = conv_trans_block_3d(self.num_filters * 8, self.num_filters * 8, activation)\n",
    "        self.up_3 = conv_block_2_3d(self.num_filters * 12, self.num_filters * 4, activation)\n",
    "        self.trans_4 = conv_trans_block_3d(self.num_filters * 4, self.num_filters * 4, activation)\n",
    "        self.up_4 = conv_block_2_3d(self.num_filters * 6, self.num_filters * 2, activation)\n",
    "        self.trans_5 = conv_trans_block_3d(self.num_filters * 2, self.num_filters * 2, activation)\n",
    "        self.up_5 = conv_block_2_3d(self.num_filters * 3, self.num_filters * 1, activation)\n",
    "        \n",
    "        # Output\n",
    "        self.out = conv_block_3d(self.num_filters, out_dim, activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Down sampling\n",
    "        down_1 = self.down_1(x) \n",
    "        pool_1 = self.pool_1(down_1) \n",
    "        \n",
    "        down_2 = self.down_2(pool_1) \n",
    "        pool_2 = self.pool_2(down_2) \n",
    "        \n",
    "        down_3 = self.down_3(pool_2) \n",
    "        pool_3 = self.pool_3(down_3) \n",
    "        \n",
    "        down_4 = self.down_4(pool_3) \n",
    "        pool_4 = self.pool_4(down_4) \n",
    "        \n",
    "        down_5 = self.down_5(pool_4) \n",
    "        pool_5 = self.pool_5(down_5) \n",
    "        \n",
    "        # Skip Connection\n",
    "        bridge = self.bridge(pool_5) \n",
    "        \n",
    "        # Upsampling\n",
    "        trans_1 = self.trans_1(bridge) \n",
    "        concat_1 = torch.cat([trans_1, down_5], dim=1) \n",
    "        up_1 = self.up_1(concat_1) \n",
    "        \n",
    "        trans_2 = self.trans_2(up_1) \n",
    "        concat_2 = torch.cat([trans_2, down_4], dim=1) \n",
    "        up_2 = self.up_2(concat_2) \n",
    "        \n",
    "        trans_3 = self.trans_3(up_2) \n",
    "        concat_3 = torch.cat([trans_3, down_3], dim=1) \n",
    "        up_3 = self.up_3(concat_3) \n",
    "        \n",
    "        trans_4 = self.trans_4(up_3) \n",
    "        concat_4 = torch.cat([trans_4, down_2], dim=1) \n",
    "        up_4 = self.up_4(concat_4) \n",
    "        \n",
    "        trans_5 = self.trans_5(up_4) \n",
    "        concat_5 = torch.cat([trans_5, down_1], dim=1) \n",
    "        up_5 = self.up_5(concat_5) \n",
    "        \n",
    "        # Output\n",
    "        out = self.out(up_5)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_dim = 3, out_dim = 3, num_filters = 4).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25,50,75], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "loss_values = []\n",
    "loss_values_test = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_loss_test = 0.0\n",
    "\n",
    "    \n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        forcet = data.to(device)\n",
    "        dispt = target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(forcet)\n",
    "        loss = criterion(outputs, dispt)\n",
    "        running_loss =+ loss.item() * forcet.size(0)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "         \n",
    "     \n",
    "    loss_values.append(running_loss / len(train_loader))\n",
    "     \n",
    "    \n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            forceTest = data.to(device)\n",
    "            dispTest = target.to(device)\n",
    "            outputs_test = model(forceTest)\n",
    "            loss = criterion(outputs_test, dispTest)\n",
    "            running_loss_test =+ loss.item() * forceTest.size(0)\n",
    "        \n",
    "    \n",
    "    loss_values_test.append(running_loss_test / len(train_loader)) \n",
    "    #scheduler.step()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_values, label = 'Training Loss')\n",
    "ax.plot(loss_values_test, label = 'Validation Loss')\n",
    "ax.set(xlabel='No. of Epochs', ylabel ='Loss',\n",
    "       title='Training Results')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "#fig.savefig(\"200ep-0.0001lr-48batchsize.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training output\n",
    "out_train = outputs.detach().cpu().numpy()\n",
    "out1_train = out_train[-1]\n",
    "out2_train = np.swapaxes(out1_train, 0, 3)\n",
    "out2_train.shape\n",
    "\n",
    "# Training output plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(out2_train[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training groundtruth\n",
    "true_train = dispt.detach().cpu().numpy()\n",
    "true1_train = true_train[-1]\n",
    "true2_train = np.swapaxes(true1_train, 0, 3)\n",
    "true2_train.shape\n",
    "\n",
    "# Training groundtruth plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(true2_train[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation output\n",
    "out_valid = outputs_test.cpu().numpy()\n",
    "out1_valid = out_valid[-1]\n",
    "out2_valid = np.swapaxes(out1_valid, 0, 3)\n",
    "out2_valid.shape\n",
    "\n",
    "# Validation output plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(out2_valid[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation set groundtruth\n",
    "true_valid = dispTest.cpu().numpy()\n",
    "true1_valid = true_valid[-1]\n",
    "true2_valid = np.swapaxes(true1_valid, 0, 3)\n",
    "true2_valid.shape\n",
    "\n",
    "# Validation set groundtruth plot\n",
    "fig = plt.figure()\n",
    "plt.imshow(true2_valid[:,:,35,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = forcet.detach().cpu().numpy()\n",
    "test_input = forceTest.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainip = np.swapaxes(train_input[-1], 0, 3)\n",
    "testip = np.swapaxes(test_input[-1], 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(true_train))\n",
    "print(np.shape(out_train))\n",
    "print(np.shape(true_valid))\n",
    "print(np.shape(out_valid))\n",
    "print(np.shape(train_input))\n",
    "print(np.shape(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('truetrain.npy', true_train)\n",
    "np.save('outtrain.npy', out_train)\n",
    "np.save('truevalid.npy', true_valid)\n",
    "np.save('outvalid.npy', out_valid)\n",
    "np.save('traininput.npy', train_input)\n",
    "np.save('testinput.npy', test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/home/oyoussef/200epochs-48batch-0.0005lr-SmoothL1Loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_raw(data: ndarray, filename):\n",
    "    \"\"\"\n",
    "    Writes data to a .raw and .mhd file.\n",
    "\n",
    "    The provided data will be written to the filesystem as a .mhd file\n",
    "    containing the information and a .raw containing the actual data.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The data which will be printed in the file.\n",
    "        filename: The name of the file. It has to end with .mhd.\n",
    "    \"\"\"\n",
    "\n",
    "    if not filename.endswith(\".mhd\"):\n",
    "        raise FileExtensionError(\"Provided file has to be of type .mhd\")\n",
    "\n",
    "    image = SimpleITK.GetImageFromArray(data)\n",
    "    f = open(filename, \"w\")\n",
    "    SimpleITK.WriteImage(image, filename)\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the data as metaimages for visualization in Paraview\n",
    "\n",
    "write_raw(out2_train, 'Training_Output.mhd')\n",
    "write_raw(true2_train, 'Training_GT.mhd')\n",
    "\n",
    "write_raw(out2_valid, 'Validation_Output.mhd')\n",
    "write_raw(true2_valid, 'Validation_GT.mhd')\n",
    "\n",
    "write_raw(trainip, 'Training_Input.mhd')\n",
    "write_raw(testip, 'Validation_Input.mhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
